#!/usr/bin/env python3

import sys
import os
import shutil
import tarfile
import json
import io
import hashlib
import argparse
import copy

parser = argparse.ArgumentParser(description="Extract docker images + metadata")
parser.add_argument("outdir", help="directory to put extracted dirs/files into")
parser.add_argument("--savetarfrags", help="save enough info to recreate tar image")
parser.add_argument("--savelayernames", help="save the list of layers")
args = parser.parse_args()

#Wrapper that SHA256s the contents of the stream.
class SHA256Pipe(io.RawIOBase):
    def __init__(self, fd):
        self.fd = fd
        self.hasher = hashlib.sha256()
    def readinto(self, b):
        l = self.fd.readinto(b)
        if l > 0:
            self.hasher.update(b[0:l])
        return l
    def hexdigest(self):
        return self.hasher.hexdigest()

#Wrapper that saves bytes from the stream for later.
class SavePipe(io.RawIOBase):
    def __init__(self, fd):
        self.fd = fd
        self.buffer = bytearray()
        self.offset = 0
    def readinto(self, b):
        l = self.fd.readinto(b)
        if l > 0:
            self.buffer += b[0:l]
        return l
    def get_bytes(self, start, stop):
        if stop:
            ret = self.buffer[start - self.offset:stop - self.offset]
            del(self.buffer[:stop - self.offset])
            self.offset += (stop - self.offset)
        else:
            ret = self.buffer[start - self.offset:]
        return ret

if args.savetarfrags:
    outbin = open(os.path.join(args.outdir, "%s.bin" % args.savetarfrags), "wb")
    outoff = open(os.path.join(args.outdir, "%s.off" % args.savetarfrags), "wt")
    off = 0
    outbincnt = 0
    tarstream = SavePipe(sys.stdin.buffer)
else:
    tarstream = sys.stdin.buffer

#Like tarfile.extract_all, but also (optionally) generates the .bin/.off data.
def extract_all(tar, outdir, offset_data):
    global outbin, outoff, off, outbincnt, tarstream
    dirs = []
    offsets = []

    for tinfo in tar:
        if args.savetarfrags:
            if tinfo.size != 0:
                outbin.write(tarstream.get_bytes(off,
                                                 offset_data + tinfo.offset_data))
                offsets.append("%s %s\n" % (outbincnt,
                                            offset_data + tinfo.offset_data - off))
                outbincnt += offset_data + tinfo.offset_data - off
                offsets.append("F %s\n" % tinfo.name)
                off = offset_data + tinfo.offset_data + tinfo.size

        if tinfo.isdir():
            dirs.append(tinfo) #Save so we can fix the mode later.
            #Go with a mode that won't prevent us from creating files/dirs later.
            tinfo = copy.copy(tinfo)
            tinfo.mode = 0o700
        tar.extract(tinfo, outdir,
                    set_attrs=not tinfo.isdir(), numeric_owner=True)

    #Reverse sort so set setattrs in the right order.
    dirs.sort(key=lambda x: x.name)
    dirs.reverse()

    #Set the attributes of dirs, since we didn't set them above.
    for tinfo in dirs:
        dirpath = os.path.join(outdir, tinfo.name)
        tar.chown(tinfo, dirpath, numeric_owner=True)
        tar.utime(tinfo, dirpath)
        tar.chmod(tinfo, dirpath)

    return offsets

def walktree(t):
    s = set()
    for f in os.scandir(t):
        st = f.stat(follow_symlinks = False)
        s.add((f.name, st.st_mode, st.st_dev, st.st_nlink, st.st_uid, st.st_gid, st.st_size))
        if f.is_dir(follow_symlinks = False):
            s |= walktree(f.path)
    return s

jsonfiles = {}
tar = tarfile.open(fileobj=tarstream, mode="r|")
for tinfo in tar:
    name = tinfo.name

    if name.endswith(".json"):
        jsonfiles[name] = json.loads(tar.extractfile(tinfo).read().decode("utf-8"))

    if name.endswith("layer.tar"):
        hashwrapper = SHA256Pipe(tar.extractfile(tinfo))
        innertar = tarfile.open(fileobj=hashwrapper, mode="r|")

        layerpath = os.path.join(args.outdir, os.path.dirname(name))
        os.mkdir(layerpath)
        print("Extracting to %s" % layerpath)
        offsets = extract_all(innertar, layerpath, tinfo.offset_data)

        #Close, then read any leftover padding so the hash is correct.
        innertar.close()
        hashwrapper.readall()

        diffidpath = os.path.join(args.outdir, hashwrapper.hexdigest())
        if os.path.isdir(diffidpath):
            print("%s already exists, skipping" % diffidpath)
            assert(walktree(diffidpath) == walktree(layerpath))
            shutil.rmtree(layerpath)
        else:
            print("Moving to %s" % diffidpath)
            os.rename(layerpath, diffidpath)

        #We don't write the offsets immediately, since we don't know the name
        # then.
        if args.savetarfrags:
            outoff.write("CD %s\n" % hashwrapper.hexdigest())
            for offset in offsets:
                outoff.write(offset)
tar.close()

json = jsonfiles[jsonfiles["manifest.json"][0]["Config"]]
diffids = [ x.split(':')[1] for x in json["rootfs"]["diff_ids"] ]

if args.savetarfrags:
    b = tarstream.get_bytes(off, None)
    outbin.write(b)
    outoff.write("%s %s\n" % (outbincnt, len(b)))

    outbin.close()
    outoff.close()

if args.savelayernames:
    with open(os.path.join(args.outdir, args.savelayernames), "w") as l:
        for did in diffids:
            l.write("%s\n" % did)
